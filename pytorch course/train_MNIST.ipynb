{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) tensor([[0.4503, 0.2002, 0.6652],\n",
      "        [0.0870, 0.9724, 0.8549]])\n"
     ]
    }
   ],
   "source": [
    "# tensor of (2,3) size\n",
    "t1 = torch.zeros(size=(2,3), dtype = torch.float32)\n",
    "t2 = torch.ones(size=(2,3), dtype = torch.float32)\n",
    "t3 = torch.rand(size=(2,3), dtype = torch.float32)\n",
    "print(t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) cpu torch.float32\n"
     ]
    }
   ],
   "source": [
    "# porp of a tensor\n",
    "print(t2.size(), t2.device, t2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a tensor to a GPU tensor\n",
    "# t2 = t2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# From NumPy to tensor and viceversa\n",
    "np_arr = np.random.rand(2,3)\n",
    "print(np_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.from_numpy(np_arr)\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr_again = t.numpy()\n",
    "np_arr_again.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks and Backpropagation\n",
    "- Define network architecture\n",
    "- While Training\n",
    "    1. Forward pass : feed input and obatain net prediction\n",
    "    2. Compute loss : compare prediction with the \"Ground Truth\"(label)\n",
    "    3. Backward padss : compute gradient of the Network parameters w.r.t to the loss function(Pytorch autograd)\n",
    "    4. Update the network params(Pytorch Optimizer)\n",
    "    5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph\n",
    "- Support for forward and backward\n",
    "- is a directed graph keeping track of all operation performed on Variables\n",
    "- Nodes represet: \n",
    "    1. Variables\n",
    "    2. Operations\n",
    "- Pytorch Autograd handled this, providing automatic differentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph crated on the fly Wh h Wx x\n",
    "x = Variable(torch.rand(1,10))\n",
    "prev_h = Variable(torch.rand(1,20))\n",
    "W_h = Variable(torch.rand(20,20))\n",
    "W_x = Variable(torch.rand(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic compontens\n",
    "- Net architecture (torch.nn.Module)\n",
    "- Dataset (torch.utils.data.Dataset)\n",
    "- Loss function + optimizer\n",
    "- Training lopp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network form scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    # inizialization of network layer\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    # function descibing Input data path through net\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size, hidden_size, num_classes = 784, 500, 10\n",
    "model = NeuralNet(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 400, 640])\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('img/cat.jpg')\n",
    "cat = TF.to_tensor(image)\n",
    "cat.unsqueeze_(0)\n",
    "print(cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = torch.rand(784)\n",
    "cat = Variable(cat.view(-1, 28*28))\n",
    "# cat should be 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1050,  0.0173, -0.1056,  0.0905,  0.0284,  0.0654, -0.2433, -0.2287,\n",
       "          0.0087, -0.0208]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_res = model(cat)\n",
    "forward_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMNIST(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # load image ( Height * Width * Channels)\n",
    "        # (H, W, C) => (C, H, W)\n",
    "        image = self.data.iloc[index,1:].values.astype(np.uint8).reshape(1, 28, 28)\n",
    "        label = self.data.iloc[index, 0]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image,label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(), \n",
    "                                transforms.RandomHorizontalFlip(0.5), \n",
    "                                transforms.ToTensor()])\n",
    "train_dataset = DatasetMNIST(file_path='input/train.csv', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# dataloader efficent iterator\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data', train=True,download=True,\n",
    "                              transform=torchvision.transforms.Compose([\n",
    "                                  torchvision.transforms.ToTensor(),\n",
    "                                  torchvision.transforms.Normalize((0.1307,),(0.3081,))\n",
    "                              ])),\n",
    "batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.rand(3,5,requires_grad=True)\n",
    "target = torch.empty(3,dtype=torch.long).random_(5)\n",
    "output = loss(input, target) # compute loss\n",
    "output.backward() # compute gradient backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# optimizer update net parameters depending on the gradient of the backward step\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "var1 = torch.rand(5)\n",
    "var2 = torch.rand(5)\n",
    "optimizer = optim.Adam([var1,var2],lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss is: 0.303763\n",
      "Epoch 1 loss is: 0.130319\n",
      "Epoch 2 loss is: 0.089105\n",
      "Epoch 3 loss is: 0.066920\n",
      "Epoch 4 loss is: 0.052757\n",
      "Epoch 5 loss is: 0.042692\n",
      "Epoch 6 loss is: 0.034716\n",
      "Epoch 7 loss is: 0.028133\n",
      "Epoch 8 loss is: 0.023180\n",
      "Epoch 9 loss is: 0.019550\n",
      "Epoch 10 loss is: 0.015843\n",
      "Epoch 11 loss is: 0.013341\n",
      "Epoch 12 loss is: 0.011330\n",
      "Epoch 13 loss is: 0.009884\n",
      "Epoch 14 loss is: 0.008542\n",
      "Epoch 15 loss is: 0.007312\n",
      "Epoch 16 loss is: 0.006317\n",
      "Epoch 17 loss is: 0.005686\n",
      "Epoch 18 loss is: 0.005048\n",
      "Epoch 19 loss is: 0.004473\n",
      "Epoch 20 loss is: 0.004065\n",
      "Epoch 21 loss is: 0.003681\n",
      "Epoch 22 loss is: 0.003383\n",
      "Epoch 23 loss is: 0.003139\n",
      "Epoch 24 loss is: 0.002917\n",
      "Epoch 25 loss is: 0.002713\n",
      "Epoch 26 loss is: 0.002538\n",
      "Epoch 27 loss is: 0.002364\n",
      "Epoch 28 loss is: 0.002247\n",
      "Epoch 29 loss is: 0.002120\n",
      "Epoch 30 loss is: 0.002005\n",
      "Epoch 31 loss is: 0.001893\n",
      "Epoch 32 loss is: 0.001818\n",
      "Epoch 33 loss is: 0.001731\n",
      "Epoch 34 loss is: 0.001662\n",
      "Epoch 35 loss is: 0.001579\n",
      "Epoch 36 loss is: 0.001510\n",
      "Epoch 37 loss is: 0.001466\n",
      "Epoch 38 loss is: 0.001401\n",
      "Epoch 39 loss is: 0.001345\n",
      "Epoch 40 loss is: 0.001297\n",
      "Epoch 41 loss is: 0.001249\n",
      "Epoch 42 loss is: 0.001215\n",
      "Epoch 43 loss is: 0.001161\n",
      "Epoch 44 loss is: 0.001133\n",
      "Epoch 45 loss is: 0.001090\n",
      "Epoch 46 loss is: 0.001061\n",
      "Epoch 47 loss is: 0.001033\n",
      "Epoch 48 loss is: 0.001001\n",
      "Epoch 49 loss is: 0.000971\n",
      "Epoch 50 loss is: 0.000946\n",
      "Epoch 51 loss is: 0.000921\n",
      "Epoch 52 loss is: 0.000896\n",
      "Epoch 53 loss is: 0.000873\n",
      "Epoch 54 loss is: 0.000850\n",
      "Epoch 55 loss is: 0.000830\n",
      "Epoch 56 loss is: 0.000811\n",
      "Epoch 57 loss is: 0.000788\n",
      "Epoch 58 loss is: 0.000773\n",
      "Epoch 59 loss is: 0.000753\n",
      "Epoch 60 loss is: 0.000738\n",
      "Epoch 61 loss is: 0.000723\n",
      "Epoch 62 loss is: 0.000707\n",
      "Epoch 63 loss is: 0.000693\n",
      "Epoch 64 loss is: 0.000676\n",
      "Epoch 65 loss is: 0.000663\n",
      "Epoch 66 loss is: 0.000651\n",
      "Epoch 67 loss is: 0.000637\n",
      "Epoch 68 loss is: 0.000624\n",
      "Epoch 69 loss is: 0.000612\n",
      "Epoch 70 loss is: 0.000603\n",
      "Epoch 71 loss is: 0.000592\n",
      "Epoch 72 loss is: 0.000580\n",
      "Epoch 73 loss is: 0.000570\n",
      "Epoch 74 loss is: 0.000560\n",
      "Epoch 75 loss is: 0.000550\n",
      "Epoch 76 loss is: 0.000541\n",
      "Epoch 77 loss is: 0.000532\n",
      "Epoch 78 loss is: 0.000522\n",
      "Epoch 79 loss is: 0.000514\n",
      "Epoch 80 loss is: 0.000506\n",
      "Epoch 81 loss is: 0.000497\n",
      "Epoch 82 loss is: 0.000489\n",
      "Epoch 83 loss is: 0.000482\n",
      "Epoch 84 loss is: 0.000475\n",
      "Epoch 85 loss is: 0.000467\n",
      "Epoch 86 loss is: 0.000460\n",
      "Epoch 87 loss is: 0.000454\n",
      "Epoch 88 loss is: 0.000447\n",
      "Epoch 89 loss is: 0.000441\n",
      "Epoch 90 loss is: 0.000436\n",
      "Epoch 91 loss is: 0.000429\n",
      "Epoch 92 loss is: 0.000423\n",
      "Epoch 93 loss is: 0.000417\n",
      "Epoch 94 loss is: 0.000411\n",
      "Epoch 95 loss is: 0.000406\n",
      "Epoch 96 loss is: 0.000399\n",
      "Epoch 97 loss is: 0.000395\n",
      "Epoch 98 loss is: 0.000390\n",
      "Epoch 99 loss is: 0.000385\n"
     ]
    }
   ],
   "source": [
    "# Training LOOP \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(100):\n",
    "    tot_loss, tot_samples = 0.0, 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Step 1 Batch of input from dataloader\n",
    "        images, labels = data\n",
    "        tot_samples += images.size(0)\n",
    "        \n",
    "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Step 2 zero grading parametes always do before backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3 get prediction\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Step 4 compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Step 5 compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step 6 optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        #logging\n",
    "        tot_loss += (loss.item()*images.size(0))\n",
    "    # End epoch\n",
    "    print(\"Epoch %d loss is: %.6f\"%(epoch,(tot_loss*1.0/float(tot_samples))))\n",
    "#End Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./model/fnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
