{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew-wYEf-5YoZ"
      },
      "source": [
        "## Import DATA PACS and gradient_reversal_example.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-gSM4i5eZZ",
        "outputId": "ecb6c651-471c-4dd4-9fa1-b096ab683838"
      },
      "source": [
        "!git clone https://github.com/MachineLearning2020/Homework3-PACS"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 10032, done.\u001b[K\n",
            "remote: Total 10032 (delta 0), reused 0 (delta 0), pack-reused 10032\u001b[K\n",
            "Receiving objects: 100% (10032/10032), 174.13 MiB | 41.92 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Checking out files: 100% (9993/9993), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G5prXKY5kpI"
      },
      "source": [
        "## ALEX NET\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJo7rO66Vm_"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "from torch.autograd import Function\r\n",
        "from torchvision import transforms\r\n",
        "from typing import Any\r\n",
        "\r\n",
        "try:\r\n",
        "    from torch.hub import load_state_dict_from_url\r\n",
        "except ImportError:\r\n",
        "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\r\n",
        "\r\n",
        "__all__ = ['AlexNet', 'alexnet']\r\n",
        "\r\n",
        "\r\n",
        "model_urls = {\r\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\r\n",
        "}\r\n",
        "\r\n",
        "class ReverseLayerF(Function):\r\n",
        "    # Forwards identity\r\n",
        "    # Sends backward reversed gradients\r\n",
        "    @staticmethod\r\n",
        "    def forward(ctx, x, alpha):\r\n",
        "        ctx.alpha = alpha\r\n",
        "\r\n",
        "        return x.view_as(x)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def backward(ctx, grad_output):\r\n",
        "        output = grad_output.neg() * ctx.alpha\r\n",
        "\r\n",
        "        return output, None\r\n",
        "\r\n",
        "\r\n",
        "class AlexNet(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self) -> None:\r\n",
        "        super(AlexNet, self).__init__()\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "        )\r\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(256 * 6 * 6, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(4096, 1000),\r\n",
        "        )\r\n",
        "        self.domain_classifier = nn.Sequential(\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(256 * 6 * 6, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(4096, 1000),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x: torch.Tensor, alpha) -> torch.Tensor:\r\n",
        "        x = self.features(x)\r\n",
        "        x = self.avgpool(x)\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        if alpha is not None:\r\n",
        "          reverse_feature_x = ReverseLayerF.apply(x, alpha)\r\n",
        "          x = self.domain_classifier(reverse_feature_x)\r\n",
        "\r\n",
        "        else:\r\n",
        "          x = self.classifier(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "def alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> AlexNet:\r\n",
        "    r\"\"\"AlexNet model architecture from the\r\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\r\n",
        "    Args:\r\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "    \"\"\"\r\n",
        "    model = AlexNet(**kwargs)\r\n",
        "    if pretrained:\r\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\r\n",
        "                                              progress=progress)\r\n",
        "        model.load_state_dict(state_dict, strict=False)\r\n",
        "        model.domain_classifier.load_state_dict(state_dict, strict=False)\r\n",
        "    return model\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HviO5cJcFOJn"
      },
      "source": [
        "## Transforms\r\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\r\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\r\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\r\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\r\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\r\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\r\n",
        "])\r\n",
        "\r\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\r\n",
        "                                      transforms.CenterCrop(224),\r\n",
        "                                      transforms.ToTensor(),\r\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \r\n",
        "])\r\n",
        "\r\n",
        "## Dataloader\r\n",
        "train_pacs_source_data = torchvision.datasets.ImageFolder('/content/Homework3-PACS/PACS/photo', train_transform)\r\n",
        "train_pacs_source_data_loader = torch.utils.data.DataLoader(train_pacs_source_data, batch_size=256, shuffle=True)\r\n",
        "\r\n",
        "test_pacs_data = torchvision.datasets.ImageFolder('/content/Homework3-PACS/PACS/art_painting', eval_transform)\r\n",
        "test_pacs_data_loader = torch.utils.data.DataLoader(test_pacs_data, batch_size=256, shuffle=True)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk5Ko1R8Gc2c"
      },
      "source": [
        "# class_prediction = net(images)\r\n",
        "# domain_prediction = net(images, alpha)\r\n",
        "LR = 0.005            # The initial Learning Rate\r\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\r\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\r\n",
        "\r\n",
        "NUM_EPOCHS = 40      # Total number of training epochs (iterations over dataset)\r\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\r\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\r\n",
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\r\n",
        "LOG_FREQUENCY = 10\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "663UNWJsI6jy"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "from torch.backends import cudnn\r\n",
        "## Model definition\r\n",
        "net = alexnet(pretrained=True)\r\n",
        "net.classifier[6] = nn.Linear(4096, 7)\r\n",
        "net.domain_classifier[6] = nn.Linear(4096, 2)\r\n",
        "# Define loss function\r\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\r\n",
        "\r\n",
        "# Choose parameters to optimize\r\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\r\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\r\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\r\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \r\n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\r\n",
        "\r\n",
        "# Define optimizer\r\n",
        "# An optimizer updates the weights based on loss\r\n",
        "# We use SGD with momentum\r\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\r\n",
        "\r\n",
        "# Define scheduler\r\n",
        "# A scheduler dynamically changes learning rate\r\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\r\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnIis5oZKhj0",
        "outputId": "e000bf92-4b59-4dc4-a30a-60749d0e1b4b"
      },
      "source": [
        "## Train\r\n",
        "# By default, everything is loaded to cpu\r\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\r\n",
        "\r\n",
        "cudnn.benchmark # Calling this optimizes runtime\r\n",
        "\r\n",
        "current_step = 0\r\n",
        "\r\n",
        "# Start iterating over the epochs\r\n",
        "for epoch in range(NUM_EPOCHS):\r\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\r\n",
        "\r\n",
        "  target_data_loader_iterator = iter(test_pacs_data_loader)\r\n",
        "  # Iterate over the dataset\r\n",
        "  for images, labels in train_pacs_source_data_loader:\r\n",
        "    # Bring data over the device of choice\r\n",
        "    images = images.to(DEVICE)\r\n",
        "    labels = labels.to(DEVICE)\r\n",
        "    labels_da_s = torch.zeros(images.size()[0], dtype=torch.long).to(DEVICE) \r\n",
        "\r\n",
        "    #target\r\n",
        "    try:\r\n",
        "      images_t, labels_t = next(target_data_loader_iterator)\r\n",
        "      images_t = images_t.to(DEVICE)\r\n",
        "      labels_da_t = torch.ones(images_t.size()[0], dtype=torch.long).to(DEVICE) \r\n",
        "\r\n",
        "    except StopIteration:\r\n",
        "      target_data_loader_iterator = iter(test_pacs_data_loader)\r\n",
        "      images_t, labels_t = next(target_data_loader_iterator)\r\n",
        "      images_t = images_t.to(DEVICE)\r\n",
        "      labels_da_t = torch.ones(images_t.size()[0], dtype=torch.long).to(DEVICE) \r\n",
        "\r\n",
        "    net.train() # Sets module in training mode\r\n",
        "\r\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\r\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\r\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\r\n",
        "\r\n",
        "    #i\r\n",
        "    outputs = net(images, None)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    #ii\r\n",
        "    outputs_da = net(images, 0.05)\r\n",
        "    loss_da = criterion(outputs_da, labels_da_s )\r\n",
        "    loss_da.backward()\r\n",
        "    #iii\r\n",
        "    outputs_da_t = net(images_t, 0.05)\r\n",
        "    loss_da_t = criterion(outputs_da_t, labels_da_t)\r\n",
        "    loss_da_t.backward()\r\n",
        "\r\n",
        "    # Log loss\r\n",
        "    if current_step % LOG_FREQUENCY == 0:\r\n",
        "      print('Step {}, Loss {}, Loss_da {}, Loss_da_t {}'.format(current_step, loss.item(), loss_da.item(), loss_da_t.item()))\r\n",
        "\r\n",
        "    # Compute gradients for each layer and update weights\r\n",
        "      # backward pass: computes gradients\r\n",
        "   \r\n",
        "    \r\n",
        "    optimizer.step() # update weights based on accumulated gradients\r\n",
        "\r\n",
        "    current_step += 1\r\n",
        "\r\n",
        "  # Step the scheduler\r\n",
        "  scheduler.step()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/40, LR = [0.005]\n",
            "Step 0, Loss 2.4364380836486816, Loss_da 0.8158575296401978, Loss_da_t 0.5731236338615417\n",
            "Starting epoch 2/40, LR = [0.005]\n",
            "Step 10, Loss 0.3586142659187317, Loss_da 0.41266006231307983, Loss_da_t 0.2559729516506195\n",
            "Starting epoch 3/40, LR = [0.005]\n",
            "Step 20, Loss 0.11831696331501007, Loss_da 0.23419296741485596, Loss_da_t 0.1717045158147812\n",
            "Starting epoch 4/40, LR = [0.005]\n",
            "Starting epoch 5/40, LR = [0.005]\n",
            "Step 30, Loss 0.05489834398031235, Loss_da 0.2712863087654114, Loss_da_t 0.09909719228744507\n",
            "Starting epoch 6/40, LR = [0.005]\n",
            "Step 40, Loss 0.048794426023960114, Loss_da 0.11181071400642395, Loss_da_t 0.20286798477172852\n",
            "Starting epoch 7/40, LR = [0.005]\n",
            "Starting epoch 8/40, LR = [0.005]\n",
            "Step 50, Loss 0.029765071347355843, Loss_da 0.10395465791225433, Loss_da_t 0.19983872771263123\n",
            "Starting epoch 9/40, LR = [0.005]\n",
            "Step 60, Loss 0.015390575863420963, Loss_da 0.06421293318271637, Loss_da_t 0.17988614737987518\n",
            "Starting epoch 10/40, LR = [0.005]\n",
            "Starting epoch 11/40, LR = [0.005]\n",
            "Step 70, Loss 0.013284265995025635, Loss_da 0.05671052634716034, Loss_da_t 0.24142710864543915\n",
            "Starting epoch 12/40, LR = [0.005]\n",
            "Step 80, Loss 0.011728759855031967, Loss_da 0.05440988764166832, Loss_da_t 0.11151526868343353\n",
            "Starting epoch 13/40, LR = [0.005]\n",
            "Step 90, Loss 0.004905825946480036, Loss_da 0.05236119031906128, Loss_da_t 0.06040608137845993\n",
            "Starting epoch 14/40, LR = [0.005]\n",
            "Starting epoch 15/40, LR = [0.005]\n",
            "Step 100, Loss 0.010383850894868374, Loss_da 0.06258890777826309, Loss_da_t 0.08341486006975174\n",
            "Starting epoch 16/40, LR = [0.005]\n",
            "Step 110, Loss 0.005476071033626795, Loss_da 0.02286566235125065, Loss_da_t 0.20514903962612152\n",
            "Starting epoch 17/40, LR = [0.005]\n",
            "Starting epoch 18/40, LR = [0.005]\n",
            "Step 120, Loss 0.009407556615769863, Loss_da 0.0963502749800682, Loss_da_t 0.07390150427818298\n",
            "Starting epoch 19/40, LR = [0.005]\n",
            "Step 130, Loss 0.0029886960983276367, Loss_da 0.048391908407211304, Loss_da_t 0.12114077806472778\n",
            "Starting epoch 20/40, LR = [0.005]\n",
            "Starting epoch 21/40, LR = [5e-05]\n",
            "Step 140, Loss 0.0011107901809737086, Loss_da 0.03254586085677147, Loss_da_t 0.1647549271583557\n",
            "Starting epoch 22/40, LR = [0.0005]\n",
            "Step 150, Loss 0.0025459423195570707, Loss_da 0.11257107555866241, Loss_da_t 0.04362950101494789\n",
            "Starting epoch 23/40, LR = [0.0005]\n",
            "Step 160, Loss 0.0018067203927785158, Loss_da 0.04490557312965393, Loss_da_t 0.11226869374513626\n",
            "Starting epoch 24/40, LR = [0.0005]\n",
            "Starting epoch 25/40, LR = [0.0005]\n",
            "Step 170, Loss 0.004491745959967375, Loss_da 0.07091952860355377, Loss_da_t 0.044127535074949265\n",
            "Starting epoch 26/40, LR = [0.0005]\n",
            "Step 180, Loss 0.0007980656228028238, Loss_da 0.06806634366512299, Loss_da_t 0.056993793696165085\n",
            "Starting epoch 27/40, LR = [0.0005]\n",
            "Starting epoch 28/40, LR = [0.0005]\n",
            "Step 190, Loss 0.002139431657269597, Loss_da 0.046969275921583176, Loss_da_t 0.06963291764259338\n",
            "Starting epoch 29/40, LR = [0.0005]\n",
            "Step 200, Loss 0.003176353173330426, Loss_da 0.05567225441336632, Loss_da_t 0.06820846349000931\n",
            "Starting epoch 30/40, LR = [0.0005]\n",
            "Starting epoch 31/40, LR = [0.0005]\n",
            "Step 210, Loss 0.003380064619705081, Loss_da 0.049609482288360596, Loss_da_t 0.10486160963773727\n",
            "Starting epoch 32/40, LR = [0.0005]\n",
            "Step 220, Loss 0.0026190616190433502, Loss_da 0.04508860409259796, Loss_da_t 0.06450528651475906\n",
            "Starting epoch 33/40, LR = [0.0005]\n",
            "Step 230, Loss 0.0016952517908066511, Loss_da 0.06758780777454376, Loss_da_t 0.06031346321105957\n",
            "Starting epoch 34/40, LR = [0.0005]\n",
            "Starting epoch 35/40, LR = [0.0005]\n",
            "Step 240, Loss 0.003654043423011899, Loss_da 0.05461867153644562, Loss_da_t 0.03310682252049446\n",
            "Starting epoch 36/40, LR = [0.0005]\n",
            "Step 250, Loss 0.0030817287042737007, Loss_da 0.05340895056724548, Loss_da_t 0.07565987855195999\n",
            "Starting epoch 37/40, LR = [0.0005]\n",
            "Starting epoch 38/40, LR = [0.0005]\n",
            "Step 260, Loss 0.002773870015516877, Loss_da 0.11381351202726364, Loss_da_t 0.04374430328607559\n",
            "Starting epoch 39/40, LR = [0.0005]\n",
            "Step 270, Loss 0.008659900166094303, Loss_da 0.05061748996376991, Loss_da_t 0.0453244224190712\n",
            "Starting epoch 40/40, LR = [0.0005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcUHVtYS0-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e20cecd-5408-47a9-f823-35f105bd4c1e"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\r\n",
        "net.train(False) # Set Network to evaluation mode\r\n",
        "\r\n",
        "running_corrects = 0\r\n",
        "for images, labels in tqdm(test_pacs_data_loader):\r\n",
        "  images = images.to(DEVICE)\r\n",
        "  #labels =  labels_da_t = torch.ones(images_t.size()[0], dtype=torch.long).to(DEVICE) \r\n",
        "  labels = labels.to(DEVICE)\r\n",
        "\r\n",
        "  # Forward Pass\r\n",
        "  outputs = net(images, None)\r\n",
        "\r\n",
        "  # Get predictions\r\n",
        "  _, preds = torch.max(outputs.data, 1)\r\n",
        "\r\n",
        "  # Update Corrects\r\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\r\n",
        "\r\n",
        "# Calculate Accuracy\r\n",
        "accuracy = running_corrects / float(len(test_pacs_data))\r\n",
        "\r\n",
        "print('Validation Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5498046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwZKfQJ8VoOI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}